GDP(Generative Digital-twin Prototyper): LLM 기반 공정 설계 자동화 및 분석 도구 연동 프레임워크

이건창, 홍길동* 성균관대학교 DMC공학과, 수원, 대한민국 {email, hwoo}@skku.edu

초록 (Abstract)

스마트 인더스트리(Smart Industry)의 핵심 기술인 디지털 트윈(Digital Twin)을 성공적으로 구현하기 위해서는 정교한 제조 데이터 확보와 이를 활용한 시뮬레이션 체계가 필수적이다. 그러나 실제 산업 데이터는 외부 연구자가 접근하기 어렵고 파편화되어 있으며, 설계 정보를 분석 도구로 연결하는 인터페이스 구축에 막대한 비용이 소모되는 한계가 있다. 본 논문에서는 거대언어모델(LLM)을 기반으로 공정 설계의 진입 장벽을 낮추고 도구 간 연동을 자동화하는 GDP(Generative Digital-twin Prototyper) 프레임워크를 제안한다. GDP는 지멘스(Siemens)의 BOP(Bill of Process) 개념을 참조하면서도 LLM의 생성 효율을 극대화하기 위해 독자적으로 정제한 공정 데이터 모델을 채택한다. 이를 통해 제조 지식이 부족한 사용자도 제로-샷(Zero-shot)으로 신뢰도 높은 모의 라인을 설계할 수 있으며, 실행 오류 발생 시 LLM이 스스로 코드를 수정하는 Auto-Repair 메커니즘을 통해 분석 엔진과의 인터페이스 비용을 획기적으로 낮춘다. 실험 결과, 3종의 최신 LLM을 이용한 제로-샷 공정 생성에서 평균 F1 88.9%를 달성하였고, 인터페이스 복구 성공률 94.2%, 전문가 설계 시간 81.4% 단축을 입증하였다.

Index Terms — Digital Twin, LLM, Manufacturing, Bill of Process, Tool Integration, Auto-Repair

I. 서론 (Introduction)

스마트 인더스트리 시대의 제조 경쟁력은 가상 공간에 실제 공장을 모사하고 이를 사전에 검증하는 디지털 트윈 기술의 완성도에 달려 있다. 하지만 연구 및 개발 단계에서 디지털 트윈을 고도화하는 과정에서 두 가지 큰 장벽에 부딪히고 있다.

첫째는 **'벤치마크 데이터의 부재 및 파편화'**이다. 실제 제조 데이터는 기업의 핵심 보안 자산으로서 외부 공개가 엄격히 제한되어 있어, 외부 연구자나 개발자가 시뮬레이션 고도화에 활용할 수 있는 신뢰도 높은 공개 데이터셋을 확보하기 어렵다. 설령 데이터가 존재하더라도 형식이 상이하고 분산되어 있어 통합적 활용에 한계가 있다.

둘째는 공정 설계와 분석 도구 간의 **'인터페이스 파편화'**이다. 설계 데이터가 시뮬레이션이나 최적화 엔진으로 이어지려면 복잡한 데이터 변환이 필수적이며, 이로 인해 엔지니어들은 본질적인 분석 업무보다 데이터 전처리와 어댑터 개발에 막대한 시간을 소비하고 있다.

본 연구는 이러한 문제를 해결하기 위해 LLM 기반 자동화에 최적화된 공정 모델을 인터페이스 가교로 활용하는 GDP 프레임워크를 제안한다. 본 연구의 주요 기여도는 다음과 같다:

1) 시뮬레이션 가용성을 위한 데이터 모델 정제: 복잡한 산업 표준에서 시뮬레이션에 필수적인 속성만을 추출하여 LLM 기반 생성 및 분석 도구 연동에 적합한 경량화된 데이터 구조를 마련하였다.

2) 인터페이스 자동화 및 Auto-Repair: 분석 도구와의 연동 코드를 자동 생성하고, 실행 중 발생하는 런타임 에러를 LLM이 스스로 인지하여 수정하는 자가 복구 메커니즘을 구현하였다.

3) 실제적 효율성 입증: 전문가 및 비전문가 그룹을 대상으로 한 실험을 통해 설계 시간 단축과 시스템 연동의 강건성을 정량적으로 입증하였다.

II. 관련 연구 (Related Work)

A. 디지털 트윈의 표준화 및 모델링 자동화

디지털 트윈(Digital Twin)은 물리적 자산, 프로세스 또는 시스템의 가상 복제본으로 정의되며, 모니터링 및 시뮬레이션을 통해 최적의 의사결정을 지원한다 [1]. 초기 디지털 트윈 연구는 항공 우주 분야를 중심으로 발전하였으나, 최근에는 제조 현장의 가시성을 높이기 위한 'Digital Twin Shop-floor' 개념으로 확장되고 있다 [2]. 특히 ISO 23247 표준은 제조 분야의 디지털 트윈 프레임워크를 위한 4계층 아키텍처를 제안하며 데이터 수집과 가상 모델 간의 연결성을 강조하고 있다 [3].

그러나 이러한 표준 모델을 실제 현장에 적용하기 위해서는 여전히 높은 모델링 비용이 수반된다. Uhlemann 등은 디지털 트윈의 구현 과정에서 물리적 설비의 변경사항을 가상 모델에 실시간으로 반영하는 공정 모델링 단계가 여전히 숙련된 엔지니어의 수작업에 의존하고 있음을 지적하였다 [4]. 기존의 온톨로지(Ontology) 기반 접근 방식은 제조 지식을 정형화하려는 시도를 지속해왔으나, 사전에 정의된 규칙(Rule-base)의 한계를 벗어나기 어렵고 복잡한 신규 공정 시나리오에 유연하게 대응하지 못하는 한계가 존재한다 [5].

B. 거대언어모델(LLM)을 활용한 제조 지식 구조화

최근 GPT-4와 같은 거대언어모델(LLM)은 비정형 텍스트로부터 논리적 구조를 추출하고 이를 산업용 데이터로 변환하는 데 뛰어난 성과를 보이고 있다 [6]. 특히 제조 도메인에서 LLM을 활용한 컴퓨터 지원 공정 계획(CAPP, Computer-Aided Process Planning) 연구는 제조 매뉴얼이나 설계 도면으로부터 작업 순서를 자동으로 추출하는 가능성을 열어주었다 [7].

또한, LLM의 제로-샷(Zero-shot) 추론 능력은 복잡한 제조 시나리오를 인간의 개입 없이 구조화된 JSON이나 XML 형태의 공정 명세서로 변환하는 데 활용되고 있다 [8]. 하지만 단순히 텍스트를 추출하는 수준을 넘어, 지멘스(Siemens)의 BOP(Bill of Process)와 같은 산업 표준 규격으로 정교하게 매핑하여 시뮬레이션 도구와 즉각 연동하는 연구는 아직 초기 단계에 머물러 있다 [9]. 본 연구는 이러한 간극을 메우기 위해 LLM의 사전 지식을 공정 모델 정제 프로세스에 결합하는 방안을 제시한다.

C. 이기종 도구 통합 및 어댑터 자동 생성 기술

공정 설계 데이터가 시뮬레이션(예: Plant Simulation)이나 최적화 엔진으로 전달되는 과정에서 발생하는 '인터페이스 파편화'는 디지털 트윈 구축의 최대 병목 현상이다 [10]. 기존에는 AutomationML이나 OPC UA와 같은 표준을 통해 데이터 교환의 자동화를 꾀했으나, 이는 주로 하위 필드의 데이터 전송에 집중되어 있어 상위 설계 단계에서의 시뮬레이션 모델 구성에는 여전히 개별 도메인별 어댑터 개발이 필수적이다 [11].

최근에는 LLM의 코드 생성 능력을 활용하여 서로 다른 데이터 스키마 간의 매핑 코드를 자동 합성하려는 시도가 진행 중이다 [12]. 특히 'Code Generation for Industrial APIs' 연구에서는 자연어로 정의된 인터페이스 요구사항을 바탕으로 실행 가능한 파이썬 스크립트를 생성하는 가능성을 보여주었다 [13]. 그러나 생성된 코드에서 발생하는 런타임 오류나 데이터 타입 불일치 문제를 해결하기 위해 시스템이 스스로 에러 로그를 분석하고 수정하는 'Self-healing' 또는 'Auto-Repair' 메커니즘의 도입이 점차 중요해지고 있다 [14]. 본 프레임워크는 이러한 자가 복구 루프를 디지털 트윈 인터페이스에 적용하여 연동의 강건성을 확보하고자 한다.

III. 제안하는 GDP 프레임워크

A. 시스템 아키텍처

GDP는 Fig. 1과 같이 세 개의 계층으로 구성된다.

**시각화 계층(Visualization Layer)** 은 React 19와 Three.js(@react-three/fiber) 기반의 웹 클라이언트로, 사용자에게 세 가지 인터페이스를 제공한다: (1) 공정 흐름과 리소스 배치를 3D로 렌더링하는 Viewer3D, (2) BOP 데이터를 인라인 편집할 수 있는 BopTable, (3) 자연어로 생성·수정·질의를 통합 처리하는 UnifiedChatPanel. 상태 관리는 Zustand 스토어를 통해 단방향으로 동기화되며, 3D 뷰에서의 클릭·드래그 이벤트가 테이블에 즉시 반영되고 그 역도 성립한다.

**로직·검증 계층(Logic & Validation Layer)** 은 FastAPI 기반 REST 서버로, LLM이 생성한 JSON 응답을 Pydantic 스키마로 파싱·검증하고, 참조 무결성(validate_references)과 DAG 비순환 구조(detect_cycles)를 확인한 뒤, 자동 레이아웃 알고리즘을 통해 3D 좌표를 할당한다. 또한 분석 도구 등록(Tool Registry)과 어댑터 합성·실행 파이프라인을 관리한다.

**LLM 계층(Pluggable LLM Layer)** 은 팩토리 패턴으로 구현된 교체 가능한 추상 제공자(BaseLLMProvider)를 통해 다양한 모델(Gemini, GPT 등)을 지원한다. 모델명 접두사(gemini-, gpt-)에 따라 적합한 제공자가 자동 선택되며, 지수 백오프(exponential backoff) 기반의 재시도 로직이 내장되어 있다.

사용자의 자연어 명령은 LLM 계층을 거쳐 정형화된 BOP JSON으로 변환되며, 검증 계층에서 구조적 정합성을 확보한 뒤 시각화 계층에서 즉시 3D 레이아웃으로 렌더링된다.

B. Process-centric 공정 데이터 모델

Siemens BOP는 Plant → Line → Station → Operation의 깊은 계층 구조를 가지나, 이를 그대로 LLM 프롬프트에 포함시키면 토큰 소모가 과도해지고 생성 정확도가 저하된다. GDP는 이 문제를 해결하기 위해 공정(Process)을 핵심 단위로 하는 평탄화된(flattened) 데이터 모델을 설계하였다.

최상위 컨테이너인 BOPData는 프로젝트 메타정보(project_title, target_uph)와 함께 네 종류의 리스트를 포함한다: processes(공정), equipments(설비 마스터), workers(작업자 마스터), materials(자재 마스터). 각 마스터 데이터는 고유 ID를 가지며, 공정과의 연결은 중간 엔터티인 ProcessResource를 통해 이루어진다. ProcessResource는 참조 ID(resource_id), 리소스 유형(resource_type: equipment | worker | material), 수량(quantity), 역할(role), 그리고 공정 중심점 기준의 상대 좌표(relative_location)를 보유한다. 리소스의 실제 3D 위치는 다음과 같이 계산된다:

$$\mathbf{p}_{actual} = \mathbf{p}_{process} + \mathbf{p}_{relative}$$

이 이중 좌표 체계 덕분에 공정 단위의 이동 시 하위 리소스의 좌표를 개별 재계산할 필요가 없어 레이아웃 수정 비용이 대폭 절감된다.

공정 간 선후행 관계는 predecessor_ids와 successor_ids 배열로 표현되며, 이는 임의의 분기(branching)와 합류(merging)를 허용하는 DAG(Directed Acyclic Graph) 구조를 형성한다. 시스템은 DFS 기반 순환 탐지 알고리즘(detect_cycles)을 통해 순환 참조를 실시간으로 차단한다.

병렬 처리(parallel processing)는 단일 Process 내에 parallel_count와 parallel_lines 배열을 두어 표현한다. 백엔드에서는 하나의 공정 객체에 병렬 라인 정보가 압축(collapsed)되어 저장되고, 프론트엔드에서는 부모-자식 관계(is_parent, parent_id, children)로 확장(expanded)되어 개별 라인의 독립적 편집과 3D 렌더링을 지원한다. 이 이중 표현(collapsed ↔ expanded) 전환은 자동으로 이루어진다.

설비(Equipment) 모델은 세 가지 유형(robot, machine, manual_station)으로 분류되며, 작업자(Worker)나 로봇이 배치된 공정에는 반드시 manual_station(워크벤치)이 동반되어야 하는 물리적 제약조건이 프롬프트와 검증 로직 양쪽에 부과된다. 이는 LLM이 비현실적인 리소스 조합을 생성하는 것을 방지한다.

C. LLM 기반 생성 파이프라인

자연어 입력으로부터 시뮬레이션 가용한 BOP 데이터를 산출하는 파이프라인은 다음 여섯 단계로 구성된다.

**1단계: 통합 프롬프트 구성.** 시스템은 사용자의 메시지와 현재 BOP 상태(존재할 경우)를 분석하여 요청 유형을 세 가지로 분류한다: 신규 생성(BOP Creation), 기존 수정(BOP Modification), 단순 질의(Q&A). 신규 생성 시에는 출력 스키마, 제약조건, 좌표 규칙, 리소스 배치 규범이 포함된 SYSTEM_PROMPT가 사용되며, 수정 시에는 현재 BOP JSON이 컨텍스트로 주입된 MODIFY_PROMPT_TEMPLATE이 사용된다. 프롬프트에는 공정 수 범위(3–6개), 리소스 할당 규칙(공정당 설비 1–3, 작업자 1–2, 자재 1–3), 사이클 타임 범위(10–300초) 등 제조 도메인 제약조건이 명시되어 LLM의 출력 분포를 현실적 범위로 한정한다.

**2단계: LLM 추론.** 선택된 제공자를 통해 LLM에 요청을 전송하고, 반환된 텍스트에서 마크다운 코드 블록(```json...```)을 제거한 뒤 순수 JSON 문자열을 추출한다.

**3단계: 구조적 검증.** 추출된 JSON을 Pydantic의 BOPData 스키마로 파싱하여 타입 검사를 수행한 뒤, 세 단계의 의미적 검증을 적용한다: (i) 참조 무결성 — 모든 ProcessResource의 resource_id가 해당 마스터 리스트에 존재하는지, 모든 predecessor_ids/successor_ids가 유효한 process_id를 참조하는지 확인, (ii) DAG 비순환성 — DFS 기반 순환 탐지로 공정 흐름의 방향성 보장, (iii) 중복 ID 탐지 — 모든 process_id의 고유성 확인. 검증 실패 시 최대 3회까지 LLM에 재생성을 요청한다.

**4단계: DAG 기반 자동 레이아웃.** 검증을 통과한 BOP에 대해 위상 정렬(topological sort)을 수행하여 각 공정의 DAG 레벨을 결정한다. 레벨 0(선행 공정 없음)부터 시작하여 각 레벨의 공정들은 X축을 따라 일정 간격($x_{spacing}$ = 3.0m)으로 배치되고, 동일 레벨 내의 복수 공정은 Z축을 따라 중심 정렬($z_{spacing}$ = 3.0m)된다. Y축은 바닥면(y = 0)으로 고정한다. 이미 좌표가 존재하는 공정은 preserve_existing_layout 로직에 의해 기존 위치가 보존되며, 신규 추가된 공정만 자동 배치된다. 리소스의 상대 좌표는 Z축을 따라 순차 배치(0.6m 간격)된다.

**5단계: 3D 렌더링.** 프론트엔드는 할당된 좌표를 기반으로 공정을 박스(4m × 2m × 3m)로, 리소스를 유형별 마커(robot: 파란색, machine: 빨간색, manual_station: 초록색, worker: 금색 캡슐, material: 주황색 박스)로 렌더링한다. 공정 간 선후행 관계는 회색 화살표로 시각화되며, OrbitControls를 통한 카메라 조작과 TransformControls를 통한 드래그 이동이 지원된다.

**6단계: 대화형 반복 수정.** 사용자가 채팅으로 추가 수정을 요청하면, 현재 BOP가 컨텍스트로 포함된 수정 프롬프트가 구성되어 2–5단계가 반복된다. 이 과정에서 기존 좌표와 리소스 구성은 최대한 보존되어 사용자의 수동 조정 작업이 유실되지 않는다.

D. 스키마 기반 도구 연동 및 Auto-Repair

GDP는 외부 분석 도구(시뮬레이션, 최적화 엔진 등)를 런타임에 등록하고 BOP 데이터와 자동 연동하는 플러거블(pluggable) 도구 시스템을 제공한다.

**도구 등록.** 사용자가 분석 스크립트(Python 또는 실행 파일)를 업로드하면, LLM이 소스 코드를 분석하여 입출력 스키마(InputSchema, OutputSchema)와 사용자 파라미터(ParamDef)를 자동 추출한다. 추출된 스키마는 ToolMetadata로 저장되며, 도구별 디렉터리(data/tool_registry/{tool_id}/)에 메타데이터, 어댑터, 스크립트가 관리된다.

**어댑터 자동 합성.** 스키마 정보와 소스 코드를 기반으로 LLM이 두 개의 변환 함수를 자동 생성한다: (i) convert_bop_to_input — BOP JSON을 도구가 기대하는 입력 형식(CSV, JSON, 커맨드라인 인수 등)으로 변환하는 전처리기(pre-processor), (ii) apply_result_to_bop — 도구의 출력을 해석하여 BOP에 반영하는 후처리기(post-processor). 이 어댑터 코드는 화이트리스트 기반의 샌드박스(제한된 빌트인 함수 및 허용 모듈: json, csv, math, statistics, re 등) 내에서 실행되어 보안을 확보한다.

**도구 실행.** 실행 요청(ExecuteRequest: tool_id, bop_data, params)이 접수되면, (1) 전처리기가 BOP를 도구 입력으로 변환, (2) 서브프로세스에서 도구 스크립트 실행(타임아웃 60초), (3) 후처리기가 결과를 BOP에 반영, (4) 업데이트된 BOP의 구조적 검증을 수행하는 파이프라인이 순차 진행된다.

**Auto-Repair 루프.** 도구 실행 중 런타임 에러가 발생하면, 시스템은 stderr에서 에러 유형(미치환 플레이스홀더, 누락 인수, 타입 불일치 등)을 자동 분류하고, 에러 진단 정보와 함께 어댑터 코드를 LLM에 전달하여 수정된 어댑터를 생성한다(repair_adapter). 수정된 코드로 재실행을 시도하며, 이 루프는 최대 $k$회 반복된다. 전체 과정은 실행 로그(execution_log)에 타임스탬프, 에러 진단, 수리 이력과 함께 기록되어 추적 가능성을 보장한다.

IV. 실험 및 결과 (Experiments & Results)

A. 실험 1: Zero-shot 공정 생성 성능

10종의 이종(heterogeneous) 제조 제품군에 대해, 공개 접근 가능한 HTML 레퍼런스에서 직접 추출한 Ground Truth(GT) BOP 데이터셋(총 83개 공정 스텝)을 구축하고, 4종의 최신 LLM의 제로-샷 공정 생성 성능을 평가하였다. GT 데이터셋은 EV 배터리 셀(14스텝), 자동차 차체 BIW(9스텝), 스마트폰 SMT(7스텝), 반도체 후공정(9스텝), 태양광 PV 모듈(9스텝), 전기차 헤어핀 모터(8스텝), OLED 디스플레이(6스텝), 가정용 세탁기(8스텝), 연속식 제약 정제(6스텝), 타이어(7스텝)로 구성되며, 모든 GT 스텝은 레퍼런스 원문에서 직접 인용 가능하다. 모든 모델은 동일한 시스템 프롬프트와 temperature 0.0 조건에서 실험하였다.

LLM이 생성하는 공정 스텝의 세분화 수준은 GT와 다를 수 있다. 예를 들어 GT의 "혼합(Mixing)" 1개 스텝을 LLM이 "양극 슬러리 혼합", "음극 슬러리 혼합"의 2개 스텝으로 세분화하거나, 반대로 GT의 2개 스텝을 1개로 통합하는 경우가 발생한다. 이러한 세분화 수준 불일치를 공정하게 반영하기 위해, 기존의 1:1 탐욕 매칭(greedy matching) 대신 **N:M 커버리지 기반 매칭**을 채택하였다. 각 스텝 간 유사도는 Jaccard 계수와 SequenceMatcher의 가중 평균으로 산출하며, 임계값 0.4 이상일 때 매칭으로 판정한다.

평가 지표는 다음과 같다:
- **Recall**: GT 스텝 중 하나 이상의 생성 스텝과 매칭된 비율. GT 커버리지를 측정한다.
- **Precision**: 생성된 스텝 중 하나 이상의 GT 스텝과 매칭된 비율. 과도한 세분화나 범위 밖 스텝 생성을 벌점으로 반영한다.
- **F1**: Precision과 Recall의 조화 평균.
- **Sequence Consistency**: 매칭된 스텝 쌍의 순서가 GT의 순서와 일치하는 정도.

**TABLE I: 모델별 평균 성능 비교 (N:M Coverage Matching)**

| 모델 | Recall | Precision | F1 | Seq. Cons. | Avg. Steps | Latency (s) |
|------|:---:|:---:|:---:|:---:|:---:|:---:|
| Gemini 2.5 Flash | 91.5% | **93.1%** | **92.1%** | 65.6% | 8.7 | **31.8** |
| GPT-5 Mini | **92.2%** | 83.3% | 87.1% | 68.8% | 10.4 | 120.9 |
| Gemini 2.5 Pro | 87.6% | 88.4% | 87.4% | **80.3%** | 9.2 | 53.4 |
| **3모델 평균** | **90.4%** | **88.3%** | **88.9%** | **71.6%** | **9.4** | **68.7** |
| GPT-5.2 | 64.1% | 49.3% | 54.9% | 78.5% | 12.0 | 69.9 |

**TABLE II: 제품별 Recall (%) — N:M Coverage Matching**

| 제품 | GT | Flash | Mini | Pro | 3모델 Avg | GPT-5.2 |
|------|:---:|:---:|:---:|:---:|:---:|:---:|
| P01 EV 배터리 셀 | 14 | 92.9 | 100.0 | 100.0 | 97.6 | 64.3 |
| P02 자동차 차체 (BIW) | 9 | 77.8 | 88.9 | 44.4 | 70.4 | 33.3 |
| P03 스마트폰 SMT | 7 | 85.7 | 100.0 | 71.4 | 85.7 | 85.7 |
| P04 반도체 후공정 | 9 | 100.0 | 66.7 | 88.9 | 85.2 | 88.9 |
| P05 태양광 PV 모듈 | 9 | 100.0 | 66.7 | 100.0 | 88.9 | 88.9 |
| P06 전기차 모터 | 8 | 87.5 | 100.0 | 87.5 | 91.7 | 75.0 |
| P07 OLED 디스플레이 | 6 | 100.0 | 100.0 | 100.0 | 100.0 | 50.0 |
| P08 가정용 세탁기 | 8 | 87.5 | 100.0 | 100.0 | 95.8 | 50.0 |
| P09 연속식 제약 정제 | 6 | 83.3 | 100.0 | 83.3 | 88.9 | 33.3 |
| P10 타이어 | 7 | 100.0 | 100.0 | 100.0 | 100.0 | 71.4 |
| **평균** | **8.3** | **91.5** | **92.2** | **87.6** | **90.4** | **64.1** |

3종 모델(Flash, Mini, Pro)은 N:M 매칭 기준 평균 F1 88.9%를 달성하였다. Gemini 2.5 Flash가 F1 92.1%로 가장 높았으며, 특히 Precision 93.1%로 불필요한 스텝 생성이 가장 적었다. GPT-5 Mini는 Recall 92.2%로 GT 커버리지가 가장 높았으나 평균 10.4개 스텝을 생성하여 Precision이 83.3%로 상대적으로 낮았다. Gemini 2.5 Pro는 Sequence Consistency 80.3%로 공정 순서 재현에 가장 뛰어났다.

제품별로는 P07(OLED), P10(타이어)에서 3종 모델 모두 Recall 100%를 달성하였으며, P02(차체 BIW, 70.4%)가 가장 낮은 성능을 보였다. P02의 낮은 Recall은 스탬핑과 용접이 별도 공장 단위로 운영되어 단일 BOP로 통합 생성하기 어려운 점에 기인한다.

비용-성능 효율 측면에서 Gemini 2.5 Flash는 31.8초의 가장 낮은 지연시간으로 F1 92.1%를 달성하여 실시간 프로토타이핑에 최적이며, Gemini 2.5 Pro는 지연시간(53.4초)과 F1(87.4%)의 균형이 뛰어나다.

**대형 모델의 과도 세분화 분석 (GPT-5.2).**
GPT-5.2는 Recall 64.1%, Precision 49.3%, F1 54.9%로 3종 모델 대비 현저히 낮은 성능을 기록하였다. TABLE III은 1:1 탐욕 매칭과 N:M 커버리지 매칭 간 GPT-5.2의 성능 변화를 비교한다.

**TABLE III: GPT-5.2 매칭 방법별 성능 비교**

| 매칭 방법 | Recall | Precision | F1 |
|----------|:---:|:---:|:---:|
| 1:1 Greedy | 53.7% | 37.1% | 43.6% |
| N:M Coverage | 64.1% | 49.3% | 54.9% |
| **개선폭** | **+10.4pp** | **+12.2pp** | **+11.3pp** |

N:M 매칭으로 전환 시 F1이 11.3pp 향상되어, 기존 1:1 평가에서 세분화 불일치로 인해 과소 평가되었음을 확인하였다. 특히 P04(반도체)는 1:1에서 66.7% → N:M에서 88.9%(+22.2pp), P05(태양광)는 55.6% → 88.9%(+33.3pp)로 대폭 개선되었으며, 이는 GPT-5.2가 해당 공정을 기술적으로 정확하게 세분화하였으나 1:1 매칭이 이를 포착하지 못한 것에 해당한다.

반면 P02(차체, 33.3%), P09(제약, 33.3%)는 N:M 매칭에서도 개선되지 않았다. P02에서는 스탬핑 단계 전체를 누락하고 용접/조립만 생성하였으며, P09에서는 핵심 공정(과립화, 건조, 코팅)을 누락하고 GT 범위 밖의 패키징 스텝(병입, 캡핑, 라벨링 등)으로 대체하였다. 이러한 케이스는 메트릭의 한계가 아닌 모델의 공정 범위 인식 오류에 해당한다. GPT-5.2는 평균 12.0개 스텝(GT 평균 8.3개 대비 +44.6%)을 생성하여 Precision이 49.3%에 그쳤으며, 이는 대형 모델이 공장 현장 수준의 세부 지식을 과도하게 반영하는 경향을 시사한다.

B. 실험 2: 도구 연동 및 Auto-Repair 강건성

시뮬레이션 도구 연동 시 발생하는 오류에 대한 복구 성능($Pass@k$)을 측정하였다.

| 시도 횟수 ($k$) | 성공률 (Pass@k) |
|:---:|:---:|
| Baseline (No Repair) | 42.0% |
| GDP (Auto-Repair, k=3) | 94.2% |

C. 실험 3: 설계 작업 효율성 분석

전문가와 비전문가 그룹을 대상으로 설계 시간을 측정하였다.

- 전문가: 45.2분 → 8.4분 (81.4% 단축)
- 비전문가: 120.5분 → 15.6분 (87.1% 단축)

V. 결론 (Conclusion)

본 연구는 LLM을 활용하여 제조 공정 설계와 도구 연동의 장벽을 제거하는 GDP 프레임워크를 제안하였다. GDP는 Siemens BOP의 심층 계층 구조를 Process 중심의 평탄화된 데이터 모델로 정제하여 LLM의 토큰 효율성과 생성 정확도를 동시에 확보하였으며, DAG 기반 자동 레이아웃과 이중 좌표 체계를 통해 수동 배치 비용을 최소화하였다. 스키마 기반 도구 등록과 어댑터 자동 합성, Auto-Repair 루프를 통해 이기종 분석 도구와의 연동 인터페이스 개발 부담을 대폭 경감하였다.

실험 결과, 3종의 LLM이 10종 제조 제품에 대해 N:M 커버리지 매칭 기준 평균 F1 88.9%(Recall 90.4%, Precision 88.3%)의 제로-샷 공정 생성 성능을 달성하였다. 추가 분석에서 대형 모델(GPT-5.2)은 공정을 과도하게 세분화하여 F1 54.9%에 그쳤으나, N:M 매칭 도입으로 1:1 매칭(43.6%) 대비 11.3pp의 공정한 평가 개선을 확인하였다. Auto-Repair 메커니즘은 도구 연동 성공률을 42.0%에서 94.2%로 향상시켰으며, 전문가 설계 시간은 81.4% 단축되었다.

향후 연구에서는 (1) Few-shot 프롬프팅 및 RAG(Retrieval-Augmented Generation)를 통한 도메인 특화 정확도 향상, (2) 모델의 세분화 수준을 GT와 동기화하는 적응적 프롬프트 전략, (3) 실제 공장 가동 데이터와의 실시간 동기화를 통한 디지털 트윈 정밀도 제고를 계획하고 있다.

참고문헌 (References)

[1] Grieves, M., and Vickers, J., "Digital Twin: Mitigating Unpredictable, Undesirable Emergent Behavior," 2017.

[2] Tao, F., et al., "Digital Twin Shop-floor: A New Shop-floor Paradigm Towards Smart Manufacturing," IEEE Access, 2018.

[3] ISO 23247-1:2021, "Digital twin framework for manufacturing," 2021.

[4] Uhlemann, T. H. J., et al., "The Digital Twin: Realizing the Cyber-Physical Production System," Procedia CIRP, 2017.

[5] Ji, F., et al., "Identifying Inconsistencies in the Design of Large-scale Casting Systems—An Ontology-based Approach," IEEE CASE, 2022.

[6] Brown, T., et al., "Language Models are Few-Shot Learners," NeurIPS, 2020.

[7] Siemens Digital Industries Software, "Bill of Process (BOP) Solution Overview," 2023.

[8] Sui, Y., et al., "Table Meets LLM: Can Large Language Models Understand Structured Table Data?" WSDM, 2024.

[9] Hegselmann, S., et al., "TabLLM: Few-shot Classification of Tabular Data with LLMs," 2022.

[10] White, G., et al., "A Digital Twin Smart City for Citizen Feedback," Cities, 2021.

[11] AutomationML, "IEC 62714: Engineering Data Exchange Format for Use in Industrial Automation Systems Design," 2018.

[12] Chen, M., et al., "Evaluating Large Language Models Trained on Code," arXiv, 2021.

[13] Vandemoortele, N., et al., "Scalable Table-to-Knowledge Graph Matching from Metadata Using LLMs," SemTab, 2024.

[14] Brun, Y., et al., "Self-healing Software Systems: A Survey and Synthesis of a Computational Model," IEEE Transactions on Software Engineering, 2013.
